---
layout: page
title: Home
---
<section class="c-archives">
<h2 class="c-archives__year">Publication</h2>
<ul class="c-archives__list">
<li class="c-archives__item">
    <p style="color: black;">Learning Reward for Robot Skills Using Large
    Language Models via Self-Alignment<br></p>
    <p style="font-size:75%;"><b>Yuwei Zeng</b>, Yao Mu, Lin Shao<br>ICML 2024<br><a href="https://openreview.net/pdf?id=Z19JQ6WFtJ">Paper</a><span class="v-separate"></span><a href="https://sites.google.com/view/rewardselfalign">Project</a><span class="v-separate"></span><a href="https://github.com/friolero/self_aligned_reward_learning">Code</a></p>
<li>
<li class="c-archives__item">
    <p style="color: black;"> Diff-lfd: Contact-aware model-based learning from visual demonstration for robotic manipulation via differentiable physics-based simulation and rendering<br></p>
    <p style="font-size:75%;">Xinghao Zhu, JingHan Ke, Zhixuan Xu, Zhixin Sun, Bizhe Bai, Jun Lv, Qingtao Liu, <b>Yuwei Zeng</b>, Qi Ye, Cewu Lu, Masayoshi Tomizuka, Lin Shao<br>CoRL 2023 (Oral)<br><a href="https://proceedings.mlr.press/v229/zhu23a/zhu23a.pdf">Paper</a><span class="v-separate"></span><a href="https://sites.google.com/view/diff-lfd">Project</a><br>
<li>
<li class="c-archives__item">
    <p style="color: black;">Learning Reward for Physical Skills using Large Language Model<br></p>
    <p style="font-size: 75%;"><b>Yuwei Zeng</b>, Yiqing Xu<br>CoRL 2023 Workshop LangRob<br><a href="https://openreview.net/forum?id=KlK1i2oBpI">Paper</a><span class="v-separate"></span><a href="https://drive.google.com/file/d/143ss4LUJzIQRhssbANCKOgbQAfXhgKz7/view">Poster</a><span class="v-separate"></span><a href="https://github.com/friolero/self_aligned_reward_learning">Code</a></p>
<li>
<li class="c-archives__item">
    <p style="color: black;">ClothesNet: An Information-Rich 3D Garment Model Repository with Simulated Clothes Environment<br></p>
    <p style="font-size:75%;">Bingyang Zhou, Haoyu Zhou, Tianhai Liang, Qiaojun Yu, Siheng Zhao, <b>Yuwei Zeng</b>, Jun Lv, Siyuan Luo, Qiancai Wang, Xinyuan Yu, Haonan Chen, Cewu Lu, Lin Shao<br>ICCV 2023<br><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ClothesNet_An_Information-Rich_3D_Garment_Model_Repository_with_Simulated_Clothes_ICCV_2023_paper.pdf">Paper</a><span class="v-separate"></span><a href="https://sites.google.com/view/clothesnet">Project</a><span class="v-separate"></span><a href="https://docs.google.com/forms/d/e/1FAIpQLSdE-cUxWSzvC-D99RqkIHI9yLHjvT_5QygszjfqxnB6vIt8vw/viewform">Dataset</a></p>
<li>

</ul>
</section>
