---
layout: page
title: Home
---
<section class="c-archives">
<h2 class="c-archives__year">Publication</h2>
<ul class="c-archives__list">
<li class="c-archives__item">
    <p>Learning Reward for Robot Skills Using Large Language Models via Self-Alignment </p><br>
    <p><b>Yuwei Zeng</b>, Yao Mu, Lin Shao</p><br>
    <p>ICML 2024</p><br>
    <p>
        <a href="https://openreview.net/pdf?id=Z19JQ6WFtJ">Paper</a><span class="v-separate"></span>
        <a href="https://sites.google.com/view/rewardselfalign">Project</a><span class="v-separate"></span>
        <a href="https://github.com/friolero/self_aligned_reward_learning">Code</a>
    </p><br>
<li>
<li class="c-archives__item">
    <p> Diff-lfd: Contact-aware model-based learning from visual demonstration for robotic manipulation via differentiable physics-based simulation and rendering </p><br>
    <p>Xinghao Zhu, JingHan Ke, Zhixuan Xu, Zhixin Sun, Bizhe Bai, Jun Lv, Qingtao Liu, <b>Yuwei Zeng</b>, Qi Ye, Cewu Lu, Masayoshi Tomizuka, Lin Shao </p><br>
    <p>CoRL 2023 (Oral)</p><br>
    <p>
        <a href="https://proceedings.mlr.press/v229/zhu23a/zhu23a.pdf">Paper</a><span class="v-separate"></span>
        <a href="https://sites.google.com/view/diff-lfd">Project</a>
    </p><br>
<li>
<li class="c-archives__item">
    <p>Learning Reward for Physical Skills using Large Language Model </p><br>
    <p><b>Yuwei Zeng</b>, Yiqing Xu</p><br>
    <p>CoRL 2023 Workshop LangRob</p><br>
    <p>
        <a href="https://openreview.net/forum?id=KlK1i2oBpI">Paper</a><span class="v-separate"></span>
        <a href="https://drive.google.com/file/d/143ss4LUJzIQRhssbANCKOgbQAfXhgKz7/view">Poster</a><span class="v-separate"></span>
        <a href="https://github.com/friolero/self_aligned_reward_learning">Code</a>
    </p><br>
<li>
<li class="c-archives__item">
    <p>ClothesNet: An Information-Rich 3D Garment Model Repository with Simulated Clothes Environment</p><br>
    <p>Bingyang Zhou, Haoyu Zhou, Tianhai Liang, Qiaojun Yu, Siheng Zhao, <b>Yuwei Zeng</b>, Jun Lv, Siyuan Luo, Qiancai Wang, Xinyuan Yu, Haonan Chen, Cewu Lu, Lin Shao</p><br>
    <p>ICCV 2023</p><br>
    <p>
        <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ClothesNet_An_Information-Rich_3D_Garment_Model_Repository_with_Simulated_Clothes_ICCV_2023_paper.pdf">Paper</a><span class="v-separate"></span>
        <a href="https://sites.google.com/view/clothesnet">Project</a><span class="v-separate"></span>
        <a href="https://docs.google.com/forms/d/e/1FAIpQLSdE-cUxWSzvC-D99RqkIHI9yLHjvT_5QygszjfqxnB6vIt8vw/viewform">Dataset</a>
    </p><br>
<li>

</ul>
</section>
